{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is notebook is my first attempt to browse and visualize the data in the Microsoft Spam Database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data is from Microsoft Malware Prediction Competition in Kaggle https://www.kaggle.com/c/microsoft-malware-prediction\n",
    "##### Some of code is borrowed from: https://www.kaggle.com/datark1/malware-prediction-eda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's load required libraries for ready data and visualizaion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1b4bed0265f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# from bs4 import BeautifulSoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbayes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBayesianRidge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mARDRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m from .least_angle import (Lars, LassoLars, lars_path, lars_path_gram, LarsCV,\n\u001b[0m\u001b[0;32m     16\u001b[0m                           LassoLarsCV, LassoLarsIC)\n\u001b[0;32m     17\u001b[0m from .coordinate_descent import (Lasso, ElasticNet, LassoCV, ElasticNetCV,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRegressorMixin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultiOutputMixin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0marrayfuncs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_float_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConvergenceWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_joblib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_split\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetaestimators\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_joblib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscorer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_check_multimetric_scoring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFitFailedWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_split\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mranking\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbalanced_accuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import requests \n",
    "import time as t\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "import os\n",
    "# print(os.listdir(\"C:/Users/Shahram/Desktop/Microsoft Spam/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The train.CSV file is almost 4GB. \n",
    "* Initially, I could not read the file as a whole so read the data in small chunks to figure out the columns and its content.\n",
    "* After discussing with Debadyuti, he suggested to define the Types of columns and then use the Pandas read_csv to read all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "        'MachineIdentifier':                                    'category',\n",
    "        'ProductName':                                          'category',\n",
    "        'EngineVersion':                                        'category',\n",
    "        'AppVersion':                                           'category',\n",
    "        'AvSigVersion':                                         'category',\n",
    "        'IsBeta':                                               'int8',\n",
    "        'RtpStateBitfield':                                     'float16',\n",
    "        'IsSxsPassiveMode':                                     'int8',\n",
    "        'DefaultBrowsersIdentifier':                            'float32',\n",
    "        'AVProductStatesIdentifier':                            'float32',\n",
    "        'AVProductsInstalled':                                  'float16',\n",
    "        'AVProductsEnabled':                                    'float16',\n",
    "        'HasTpm':                                               'int8',\n",
    "        'CountryIdentifier':                                    'int16',\n",
    "        'CityIdentifier':                                       'float32',\n",
    "        'OrganizationIdentifier':                               'float16',\n",
    "        'GeoNameIdentifier':                                    'float16',\n",
    "        'LocaleEnglishNameIdentifier':                          'int16',\n",
    "        'Platform':                                             'category',\n",
    "        'Processor':                                            'category',\n",
    "        'OsVer':                                                'category',\n",
    "        'OsBuild':                                              'int16',\n",
    "        'OsSuite':                                              'int16',\n",
    "        'OsPlatformSubRelease':                                 'category',\n",
    "        'OsBuildLab':                                           'category',\n",
    "        'SkuEdition':                                           'category',\n",
    "        'IsProtected':                                          'float16',\n",
    "        'AutoSampleOptIn':                                      'int8',\n",
    "        'PuaMode':                                              'category',\n",
    "        'SMode':                                                'float16',\n",
    "        'IeVerIdentifier':                                      'float16',\n",
    "        'SmartScreen':                                          'category',\n",
    "        'Firewall':                                             'float16',\n",
    "        'UacLuaenable':                                         'float64', # was 'float32'\n",
    "        'Census_MDC2FormFactor':                                'category',\n",
    "        'Census_DeviceFamily':                                  'category',\n",
    "        'Census_OEMNameIdentifier':                             'float32', # was 'float16'\n",
    "        'Census_OEMModelIdentifier':                            'float32',\n",
    "        'Census_ProcessorCoreCount':                            'float16',\n",
    "        'Census_ProcessorManufacturerIdentifier':               'float16',\n",
    "        'Census_ProcessorModelIdentifier':                      'float32', # was 'float16'\n",
    "        'Census_ProcessorClass':                                'category',\n",
    "        'Census_PrimaryDiskTotalCapacity':                      'float64', # was 'float32'\n",
    "        'Census_PrimaryDiskTypeName':                           'category',\n",
    "        'Census_SystemVolumeTotalCapacity':                     'float64', # was 'float32'\n",
    "        'Census_HasOpticalDiskDrive':                           'int8',\n",
    "        'Census_TotalPhysicalRAM':                              'float32',\n",
    "        'Census_ChassisTypeName':                               'category',\n",
    "        'Census_InternalPrimaryDiagonalDisplaySizeInInches':    'float32', # was 'float16'\n",
    "        'Census_InternalPrimaryDisplayResolutionHorizontal':    'float32', # was 'float16'\n",
    "        'Census_InternalPrimaryDisplayResolutionVertical':      'float32', # was 'float16'\n",
    "        'Census_PowerPlatformRoleName':                         'category',\n",
    "        'Census_InternalBatteryType':                           'category',\n",
    "        'Census_InternalBatteryNumberOfCharges':                'float64', # was 'float32'\n",
    "        'Census_OSVersion':                                     'category',\n",
    "        'Census_OSArchitecture':                                'category',\n",
    "        'Census_OSBranch':                                      'category',\n",
    "        'Census_OSBuildNumber':                                 'int16',\n",
    "        'Census_OSBuildRevision':                               'int32',\n",
    "        'Census_OSEdition':                                     'category',\n",
    "        'Census_OSSkuName':                                     'category',\n",
    "        'Census_OSInstallTypeName':                             'category',\n",
    "        'Census_OSInstallLanguageIdentifier':                   'float16',\n",
    "        'Census_OSUILocaleIdentifier':                          'int16',\n",
    "        'Census_OSWUAutoUpdateOptionsName':                     'category',\n",
    "        'Census_IsPortableOperatingSystem':                     'int8',\n",
    "        'Census_GenuineStateName':                              'category',\n",
    "        'Census_ActivationChannel':                             'category',\n",
    "        'Census_IsFlightingInternal':                           'float16',\n",
    "        'Census_IsFlightsDisabled':                             'float16',\n",
    "        'Census_FlightRing':                                    'category',\n",
    "        'Census_ThresholdOptIn':                                'float16',\n",
    "        'Census_FirmwareManufacturerIdentifier':                'float16',\n",
    "        'Census_FirmwareVersionIdentifier':                     'float32',\n",
    "        'Census_IsSecureBootEnabled':                           'int8',\n",
    "        'Census_IsWIMBootEnabled':                              'float16',\n",
    "        'Census_IsVirtualDevice':                               'float16',\n",
    "        'Census_IsTouchEnabled':                                'int8',\n",
    "        'Census_IsPenCapable':                                  'int8',\n",
    "        'Census_IsAlwaysOnAlwaysConnectedCapable':              'float16',\n",
    "        'Wdft_IsGamer':                                         'float16',\n",
    "        'Wdft_RegionIdentifier':                                'float16',\n",
    "        'HasDetections':                                        'int8'\n",
    "        }\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"C:/Users/Shahram/Desktop/Microsoft Spam/train.csv\", dtype=dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ref: https://www.kaggle.com/c/microsoft-malware-prediction/discussion/76384#449402\n",
    "\n",
    "base_url = 'https://www.microsoft.com/en-us/wdsi/definitions/antimalware-definition-release-notes?RequestVersion='\n",
    "#read the data the delete it then..\n",
    "#do the same for test set as well..\n",
    "\n",
    "df = pd.read_csv('train.csv', usecols=['AvSigVersion'])\n",
    "search_ver = np.asarray(list(set(df['AvSigVersion'].values)))\n",
    "del df\n",
    "\n",
    "print(len(search_ver))\n",
    "\n",
    "saved, cnt = {}, 0\n",
    "\n",
    "for i in search_ver:\n",
    "    if cnt%200 == 0:\n",
    "        print('Done till', cnt, 'out of', len(search_ver))\n",
    "\n",
    "    page = requests.get(base_url+i)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    try:\n",
    "        saved[i] = soup.find(id='availabledate').contents[0][28:]\n",
    "    except Exception:\n",
    "        print('Didn\\'t Find For', i)\n",
    "    cnt+= 1\n",
    "np.save('train_AvSigVersion.npy', saved)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT TIMESTAMP DICTIONARY\n",
    "datedict = np.load('C:/Users/Shahram/Desktop/Microsoft Spam/AvSigVersionTimestamps.npy', allow_pickle=True)\n",
    "datedict = datedict[()]\n",
    "# ADD TIMESTAMPS\n",
    "train['Date'] = train['AvSigVersion'].map(datedict)\n",
    "#df_test['Date'] = df_test['AvSigVersion'].map(datedict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see the data and its columns:\n",
    "* There are almost 8.921 Million records with 83 columns. Memory usage is around 1.9 GB. the columns type is as we defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will explore the number of unique products and the Engione version in this data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"There are\", len (train.ProductName.unique().tolist()), \"distinct products.\", train.ProductName.unique().tolist())\n",
    "print (\"There are\", len (train.EngineVersion.unique()), \"distinct version of these products.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at distribution of the Devices where a malware has been detected.\n",
    "#### It is clear that the there is equal distribution of devices with malware detected and device without any malware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zero = (train['HasDetections']==0).sum()\n",
    "One  = (train['HasDetections']==1).sum()\n",
    "sizes = [Zero,One]\n",
    "labels = ['Zero','One']\n",
    "fig1, ax1 = plt.subplots()\n",
    "plt.title(\"Check the dsitribution of whether Devices have Detection or not\", fontdict=None, loc='center', pad=None, color = \"azure\")\n",
    "ax1.pie(sizes, labels = labels, autopct='%1.1f%%',shadow=True, startangle=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see which columns are binary: \n",
    "###### I wrote the code myself but got help from https://www.kaggle.com/datark1/malware-prediction-eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindBinaryColumns (data):\n",
    "    BinaryColumns = []\n",
    "    for column in data.select_dtypes (include = ['int8', 'int16', 'int32', 'int16', 'float32', 'float64']):\n",
    "        if ( data [column].min()) == 0 or (data[column].max() == 1):\n",
    "            BinaryColumns.append (column)\n",
    "    return BinaryColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BinaryColumns = FindBinaryColumns(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('There are', len(FindBinaryColumns(train)),'columns which are Binary.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's visually look at the percentage of zeros and ones in Digital columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "for i, num in zip(BinaryColumns, range(1,20)):\n",
    "    Zero = (train[i]==0).sum()\n",
    "    One = (train[i]==1).sum()\n",
    "    sizes = [Zero,One]\n",
    "    labels = ['Zero','One']\n",
    "    ax = fig.add_subplot(4,4,num) #fig1, ax1 = plt.subplots()\n",
    "    plt.title(i, fontdict=None, loc='center', pad=None, color = \"azure\")\n",
    "    ax.pie(sizes, labels = labels, autopct='%1.1f%%',shadow=True, startangle=90)\n",
    "    ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We should take a look to see if the columns are correlated.\n",
    "##### As one can see aside from few columns ( which are in the vicinity of each other, the rest of the data are NOT Correlated.\n",
    "##### Few columns are negatively correlated. (e.g.: RtpStateBitField - IsSXSPassiveMode)\n",
    "\n",
    "\n",
    "#### Reference: https://towardsdatascience.com/better-heatmaps-and-correlation-matrix-plots-in-python-41445d0f2bec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = train.corr()\n",
    "plt.figure(figsize=(22,12))\n",
    "ax = sns.heatmap(corr, vmin=-1, vmax=1, center=0, cmap=sns.diverging_palette(20, 220, n=200), square=True)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting the number of Null values in columns and calculating the percentages\n",
    "#### We can use this conclusion to find out which columns we can drop from our calculations.\n",
    "#### As one can see, there are 7 columns with more than 50% row of null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenMissingValueTable (data):\n",
    "    NoEmptyRows = []\n",
    "    percentages = []\n",
    "    ColumnType = []\n",
    "\n",
    "    for col in train:\n",
    "        ColumnType.append(data[col].dtype)\n",
    "        NoEmptyRows.append(data[col].isnull().sum())\n",
    "        percentages.append((data[col].isnull().sum()/train.shape[0])*100)\n",
    "    \n",
    "    MissingValueTable = pd.DataFrame ({'Column Name': data.columns, 'Data Type': ColumnType, \n",
    "                                   'Number of Empty Rows': NoEmptyRows,'Percentages':percentages})\n",
    "    \n",
    "    return MissingValueTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MissingValueTable =  GenMissingValueTable (train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MissingValueTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Missing Value Percentages\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title(\"Percentage of Null counts in columns\", fontdict=None, loc='center', pad=None)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.bar(x = MissingValueTable['Column Name'], height = MissingValueTable['Percentages'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's group infected machines by the \"platform\".\n",
    "#### Windows 10 is the major infected platform with more than 4 million machines infected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = ['Platform', 'HasDetections']\n",
    "test = train.groupby(group).size().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = pd.DataFrame (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Missing Value Percentages\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"Machine counts\", fontdict=None, loc='center', pad=None)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.ylabel(\"Number of machines\") #ax.set_ylabel('Probability density')\n",
    "sns.barplot(x = test.index, y = Test[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's group infected machines by Form Factor.\n",
    "\n",
    "#### It is clear that Notebooks are majorly hit by malwares and then desktops and convertibles stand second and third respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = ['Census_MDC2FormFactor', 'HasDetections']\n",
    "test = train.groupby(group).size().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = pd.DataFrame (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Missing Value Percentages\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"Machine counts by Form Factor\", fontdict=None, loc='center', pad=None)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.ylabel(\"Number of machines\") \n",
    "sns.barplot(x = test.index, y = Test[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's group infected machines by whether they are a Gamer or not.\n",
    "#### It is clear that the gamer machine (wehether infected or not) are more than half of the non-gamers. Clearly, among the gamer machine infection is more (probable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = ['Wdft_IsGamer', 'HasDetections']\n",
    "test = train.groupby(group).size().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = pd.DataFrame (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Missing Value Percentages\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"Machine counts by whether it is a gaming machine\", fontdict=None, loc='center', pad=None)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.ylabel(\"Number of machines\") \n",
    "sns.barplot(x = test.index, y = Test[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BinaryColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CategoryColumns = train.select_dtypes (include = ['category']).columns\n",
    "# CategoryColumns\n",
    "BinaryColumns.extend(CategoryColumns)\n",
    "CategoryColumns\n",
    "# BinaryColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColumnsExcluded = train.columns.difference(BinaryColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "for i, num in zip(ColumnsExcluded, range(1,30)):\n",
    "    \n",
    "    ax = fig.add_subplot(5,6,num) #fig1, ax1 = plt.subplots()\n",
    "    plt.title(i, fontdict=None, loc='center', pad=None, color = \"azure\")\n",
    "    sns.distplot(train[i].dropna())\n",
    "    #ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "* We used the data in Microsoft Malware database.\n",
    "* The data contain around 8.92 million record and 83 column. Fifteen columns are binary. We made a pie chart to see the distributoion of the Binary columns.\n",
    "* The Target column which is HasDetectiosn is equally distributed.\n",
    "* We graphed the heatmap of correlation of columns and saw that few columns are correlted. (Two columns are strongly negatively correlated and a few are positivley correlated.)\n",
    "* we also grahphed the malware infected devices by platform and Form Factor and Windows versio.\n",
    "* Windos 10 and laptops are the most infected machines.\n",
    "* We also graphed the histogram of the rmeainning columns to see the distribution of the data.\n",
    "* Few columns (around 7) have more than 50% of their data mssining (Null value) and hence might be a good idea to ignore them in the data engineering. We ideate that the other columns with less missing values can be filled with mean or median of the column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The rest of this note book is related to Feature Engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I am going to drop the columns with more than 10% missing vlaues which are around 9 or 10 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"There are \", (MissingValueTable['Percentages']>=10).sum(), \"columns with more than 10 % of rows with missing values.\")\n",
    "MissingValueTable [(MissingValueTable['Percentages']>=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(MissingValueTable [(MissingValueTable['Percentages']>=10)]['Column Name'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are 35 columns with between 0 to 10 % rows missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MissingValueTable [(MissingValueTable['Percentages']<=10) & (MissingValueTable['Percentages']>0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MissingValueTable [(MissingValueTable['Percentages']<=10) & (MissingValueTable['Percentages']>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColumnsWMissingValue = MissingValueTable [(MissingValueTable['Percentages']<=10) & (MissingValueTable['Percentages']>0)] #['Column Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColumnsWMissingValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of Categorical columns with between 0 - 10 percent missing rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColumnsWMissingValue.loc [ColumnsWMissingValue['Data Type'] =='category']['Column Name'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since we cannot impute text at the moment, We are going to remove any rows with missing value in the categorical columns and then take a 1 or 2% sample from the rest of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train [ColumnsWMissingValue.loc [ColumnsWMissingValue['Data Type'] =='category']['Column Name'].tolist()].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ColumnsWMissingValue.loc [ColumnsWMissingValue['Data Type'] =='category']['Column Name'].tolist()\n",
    "train1 = train.dropna (subset = ColumnsWMissingValue.loc [ColumnsWMissingValue['Data Type'] =='category']['Column Name'].tolist() , axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 [ColumnsWMissingValue.loc [ColumnsWMissingValue['Data Type'] =='category']['Column Name'].tolist()].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 [ColumnsWMissingValue.loc [ColumnsWMissingValue['Data Type'] =='category']['Column Name'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train1.sample(frac=0.02,random_state=200) #random state is a seed value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will be imputating Using Multivariate Imputation by Chained Equation.\n",
    "* Ref: https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColumnsWMissingValue['Column Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumColumnWMissingValue1 = train2 [ColumnsWMissingValue['Column Name']].select_dtypes(exclude='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumColumnWMissingValue1 = NumColumnWMissingValue1.drop(\"Date\", axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumColumnWMissingValue1.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Tried Multivariate Imputation but found it to be slow \n",
    "from impyute.imputation.cs import mice\n",
    "imputed_training = mice(NumColumnWMissingValue1.values)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp_mean = SimpleImputer(strategy='mean') \n",
    "imp_mean.fit(NumColumnWMissingValue)\n",
    "imputed_train_df = imp_mean.transform(NumColumnWMissingValue)\n",
    "\n",
    "dataset = pd.DataFrame(imputed_training)\n",
    "\n",
    "dataset.columns = NumColumnWMissingValue1.columns.tolist()\n",
    "\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumColumnWMissingValue1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BinaryColumns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for col in NumColumnWMissingValue1.columns.tolist():\n",
    "    if col in BinaryColumns:\n",
    "        print (col, 'Binary')\n",
    "        print (train2[col].mode())\n",
    "    else:\n",
    "        \n",
    "        print ('Not in Binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train2 ['Census_PrimaryDiskTotalCapacity'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in NumColumnWMissingValue1.columns.tolist():\n",
    "    if col in BinaryColumns:\n",
    "        train2[col].fillna(train2[col].mode(), inplace = True)\n",
    "    else:\n",
    "        train2[col] =  train2[col].astype (dtype = 'float32')\n",
    "        train2[col].fillna(train2[col].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train2['RtpStateBitfield'].fillna(train2['RtpStateBitfield'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let digitize the categorical columns with one hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2.select_dtypes(include='category').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns = train2.select_dtypes(include='category').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Categorical_Columns = ['ProductName', 'Platform', 'Processor', 'Census_OSArchitecture',\n",
    "                       'Census_FlightRing','Census_GenuineStateName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop_columns = [x for x in train_columns if x not in Categorical_Columns]\n",
    "print (Drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train2.drop (Drop_columns, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2[Categorical_Columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2[Categorical_Columns] = train2[Categorical_Columns].astype ('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2[Categorical_Columns].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Categorical_Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3 = pd.get_dummies (train2[Categorical_Columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train2.drop (Categorical_Columns, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train4 = pd.concat([train2, train3], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train4.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timer Function: \n",
    "# Ref: https://www.kaggle.com/tilii7/hyperparameter-grid-search-with-xgboost\n",
    "from datetime import datetime\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(train4, test_size=0.3)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train4.loc[:, train4.columns != 'HasDetections'].columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.remove ('Census_InternalBatteryNumberOfCharges')\n",
    "features.remove ('Census_OEMModelIdentifier')\n",
    "features.remove ('UacLuaenable')\n",
    "features.remove ('Census_PrimaryDiskTotalCapacity')\n",
    "features.remove ('Census_SystemVolumeTotalCapacity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['HasDetections']\n",
    "X_train = train[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test['HasDetections']\n",
    "X_test = test[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ref: https://towardsdatascience.com/a-beginners-guide-to-xgboost-87f5d4c30ed7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_train = xgb.DMatrix(X_train, label=y_train)\n",
    "D_test = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param = {\n",
    "#    'eta': 0.3, \n",
    "#    'max_depth': 10,  \n",
    "#    'objective': 'multi:softprob',  \n",
    "#  'num_class': 5}\n",
    "\n",
    "param = {'subsample': 0.6, 'min_child_weight': 5, 'max_depth': 5, 'gamma': 1, 'colsample_bytree': 0.6, 'num_class': 5 , 'objective': 'multi:softprob'}\n",
    "\n",
    "steps = 20  # The number of training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = xgb.train(param, D_train, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "\n",
    "y_predict_XGB = XGB.predict(D_test)\n",
    "best_preds = np.asarray([np.argmax(line) for line in y_predict_XGB])  # I need to investigate more about this line\n",
    "cm_XGB = confusion_matrix(y_test, best_preds)\n",
    "\n",
    "print(\"Precision = {}\".format(precision_score(y_test, best_preds, average='macro')))\n",
    "print(\"Recall = {}\".format(recall_score(y_test, best_preds, average='macro')))\n",
    "print(\"Accuracy = {}\".format(accuracy_score(y_test, best_preds)))\n",
    "print (\"Confusion Matrix is:\")\n",
    "print (cm_XGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: https://www.kaggle.com/tilii7/hyperparameter-grid-search-with-xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [2, 5, 10]\n",
    "        #'num_class': [1, 5, 10]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic', silent=True, nthread=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "param_comb = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=4, cv=skf.split(X_train,y_train), verbose=3, random_state=1001 )\n",
    "\n",
    "# Here we go\n",
    "start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "random_search.fit(X_train, y_train)\n",
    "timer(start_time) # timing ends here for \"start_time\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n All results:')\n",
    "print(random_search.cv_results_)\n",
    "print('\\n Best estimator:')\n",
    "print(random_search.best_estimator_)\n",
    "print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "print(random_search.best_score_ * 2 - 1)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search.best_params_)\n",
    "results = pd.DataFrame(random_search.cv_results_)\n",
    "results.to_csv('xgb-random-grid-search-results-01.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ref: https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import lightgbm as lgb\n",
    "d_train = lgb.Dataset(X_train, label=y_train)\n",
    "params = {}\n",
    "params['learning_rate'] = 0.003\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['objective'] = 'binary'\n",
    "params['metric'] = 'binary_logloss'\n",
    "params['sub_feature'] = 0.5\n",
    "params['num_leaves'] = 100\n",
    "params['min_data'] = 50\n",
    "params['max_depth'] = 100\n",
    "clf = lgb.train(params, d_train, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Prediction\n",
    "y_pred=clf.predict(X_test)\n",
    "#convert into binary values\n",
    "for i in range(0,99):\n",
    "    if y_pred[i]>=.5:       # setting threshold to .5\n",
    "       y_pred[i]=1\n",
    "    else:  \n",
    "       y_pred[i]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "#Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy=accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.select_dtypes (include = ['float64']).isna().sum() # df.select_dtypes(include=['bool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "DTC = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DTC = DTC.fit(X_train, y_train)\n",
    "DTC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_DT = DTC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_DT = confusion_matrix(y_test, y_predict_DT)\n",
    "\n",
    "print(\"Precision = {}\".format (round (precision_score(y_test, y_predict_DT, average='macro'),3)))\n",
    "print(\"Recall = {}\".format    (round (recall_score(y_test, y_predict_DT, average='macro'),3)))\n",
    "print(\"Accuracy = {}\".format  (round (accuracy_score(y_test, y_predict_DT),3)))\n",
    "print (\"Confusion Matrix is:\")\n",
    "print (cm_DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(penalty = 'l1', C = 10,random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_LR = LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_LR = confusion_matrix(y_test, y_predict_LR)\n",
    "\n",
    "print(\"Precision = {}\".format(round(precision_score(y_test, y_predict_LR, average='macro'),3)))\n",
    "print(\"Recall = {}\".format(round (recall_score(y_test, y_predict_LR, average='macro'),3)))\n",
    "print(\"Accuracy = {}\".format(round (accuracy_score(y_test, y_predict_LR),3)))\n",
    "print (\"Confusion Matrix is:\")\n",
    "print (cm_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#This splits the data into into the training and the validation sets. The validation set is used to find the metaparameter values\n",
    "complexity = [0.1, 1,2.0]\n",
    "\n",
    "lg = LogisticRegression(penalty = 'l1', random_state = 1)\n",
    "parameters = {'C': complexity}   \n",
    "#REPLACE THIS LIST OF PARAMETERS WITH A LONGER LIST OF PARAMETERS TO TEST DIFFERENT MODELS, use very large and very small numbers\n",
    "#THIS PARAMETER IS KNOWN AS A METAPARAMETER - see the documentation to read about what this parameter means\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "####EXPLANATION########\n",
    "#THE LOGISTIC FUNCTION TAKES IN A LINEAR COMBINATION OF INPUTS IN THE FORM Xi = Ax1i + Bx2i + .....\n",
    "#A, B are parameters of the problem and x1 and x2 are features or predictive variables\n",
    "#When we need to fit the problem to many predictors, overfitting can result.\n",
    "#The output of the function, Yi, is between 0 and 1: 1 = 1/(1 + exp(-Xi)) where i is the ith data example\n",
    "#The cost function for logistic regression is usually the cross entropy = sum over i(Tilog(Yi))\n",
    "#Here, regularization (discussed in the lectures) or ridge regression is used: Cost Function = Cross Entropy +A/C  +B/C +....\n",
    "#The added terms A/C and B/C prevent over-fitting by keeping the parameter values of the model small\n",
    "#regularization can be done using absolute value of the parameter ('l1')\n",
    "#and it can be done using the square of the value of the parameter('l2') \n",
    "#small values of C constrain the parameter (or coefficient) values (A,B) to be small\n",
    "#large values of C do not constrain the parameters very much and approach the result using no regularization\n",
    "#but how to we know how big to make the regularization parameter C ?\n",
    "\n",
    "\n",
    "###ASSIGNMENT####\n",
    "#Fit this logistic regression with a dictionary of values for C, instead of just one value\n",
    "#And see which is the best value for the metaparameter, using the accuracy score, as defined below\n",
    "#Plot the accuracy as a function of C for the cross validation set and the training set\n",
    "\n",
    "\n",
    "# Use classification accuracy to compare parameter combinations\n",
    "acc_scorer_lg = make_scorer(accuracy_score)  #accuracy score is defined as a function in sklearn metrics. It computes the number of properly classified outputs\n",
    "\n",
    "\n",
    "\n",
    "# Run a grid search for the Logistic Regression classifier and all the selected parameters\n",
    "grid_obj_lg = GridSearchCV(lg, parameters, scoring=acc_scorer_lg, return_train_score=True) #parameters are arguments to the lg classifier algorithm\n",
    "grid_obj_lg = grid_obj_lg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set our classifier, lg, to have the best combination of parameters\n",
    "GridCVoutput = grid_obj_lg.cv_results_#Find the attribute that shows the output of the GridSearchCV program from the documentation\n",
    "\n",
    "#Go to the documentation to find out how to output the results of GridCVoutput for all the parameter choices:\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "print(pd.DataFrame(GridCVoutput)) #Print out the Output\n",
    "\n",
    "GSCVError = 1 - pd.DataFrame(GridCVoutput).mean_test_score  #prediction error on cross validation set for each value of C\n",
    "GSTrError = 1 - pd.DataFrame(GridCVoutput).mean_train_score  #prediction error on training set for each value of C\n",
    "\n",
    "\n",
    "lg = grid_obj_lg.best_estimator_  #3.\tSee which is the best value for the metaparameter, using the accuracy score, as defined below\n",
    "print(\"best accuracy score: %f\" % grid_obj_lg.best_score_)\n",
    "# Fit the selected classifier to the training data. \n",
    "lg.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"Underfitting\")\n",
    "    \n",
    " \n",
    "      \n",
    "plt.xlabel(\"Complexity, C = 1/lambda\")\n",
    "plt.ylabel(\"error_rate\")\n",
    "plt.plot(complexity, GSCVError, 'o-', color=\"r\", label=\"Mean Cross Validation Error Rate from GridSearchCV\")\n",
    "plt.plot(complexity, GSTrError, 'o-', color=\"g\", label=\"Mean Cross Validation Error Rate from GridSearchCV\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5921311107369366\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-48a3bdab9d85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Explain why the accuracy printed here is not the same as that in the plot below or in the output from the GridSearchCV function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Which value of the accuracy is expected for the estimates of outcomes from data the estimator has not seen before?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mX_shuf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_shuf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mplot_learning_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Logistic Regression'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_shuf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_shuf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "predictions_lg = lg.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions_lg))\n",
    "#Explain why the accuracy printed here is not the same as that in the plot below or in the output from the GridSearchCV function\n",
    "#Which value of the accuracy is expected for the estimates of outcomes from data the estimator has not seen before?\n",
    "X_shuf, y_shuf = shuffle(X, y)\n",
    "\n",
    "plot_learning_curve(lg, 'Logistic Regression', X_shuf, y_shuf, cv=4)\n",
    "\n",
    "#Explain why the accuracy of the learning curve decreases with the number of training examples for the training score, \n",
    "#but increases with the number of examples for the cross-validation score\n",
    "#consider over-fitting in your answer\n",
    "#What is the difference between the accuracy quoted in the learning curve and the accuracy you plotted as a function of C?\n",
    "#Given the outcomes for the cross validation accuracy and training accuracy as a function of the parameter values, C, do you think \n",
    "#that regularization is helpful here? Refer to the lecture notes on regularization and the sklearn documentation on logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=4,\n",
    "                            n_informative=2, n_redundant=0,\n",
    "                            random_state=0, shuffle=False)\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2,\n",
    "                              random_state=0)\n",
    "clf.fit(X, y)  \n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "print(clf.feature_importances_)\n",
    "[0.14205973 0.76664038 0.0282433  0.06305659]\n",
    "print(clf.predict([[0, 0, 0, 0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Census_PrimaryDiskTotalCapacity                      float64\n",
    "Census_PrimaryDiskTypeName                           category\n",
    "Census_SystemVolumeTotalCapacity                     float64\n",
    "Census_HasOpticalDiskDrive                           int8\n",
    "Census_TotalPhysicalRAM                              float32\n",
    "Census_ChassisTypeName                               category\n",
    "Census_InternalPrimaryDiagonalDisplaySizeInInches    float32\n",
    "Census_InternalPrimaryDisplayResolutionHorizontal    float32\n",
    "Census_InternalPrimaryDisplayResolutionVertical      float32\n",
    "Census_PowerPlatformRoleName                         category\n",
    "Census_InternalBatteryType                           category\n",
    "Census_InternalBatteryNumberOfCharges    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6242876    4.294967e+09\n",
       "6061327    0.000000e+00\n",
       "7929053    0.000000e+00\n",
       "5618420             NaN\n",
       "5639040    0.000000e+00\n",
       "               ...     \n",
       "1276185    0.000000e+00\n",
       "3207980    0.000000e+00\n",
       "5812288    0.000000e+00\n",
       "4506697    0.000000e+00\n",
       "498537     4.294967e+09\n",
       "Name: Census_InternalBatteryNumberOfCharges, Length: 124716, dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Census_InternalBatteryNumberOfCharges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
