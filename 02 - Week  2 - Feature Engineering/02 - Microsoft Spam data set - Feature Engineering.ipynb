{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is notebook is my first attempt to browse and visualize the data in the Microsoft Spam Database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data is from Microsoft Malware Prediction Competition in Kaggle https://www.kaggle.com/c/microsoft-malware-prediction\n",
    "##### Some of code is borrowed from: https://www.kaggle.com/datark1/malware-prediction-eda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's load required libraries for ready data and visualizaion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import requests \n",
    "import time as t\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import os\n",
    "# print(os.listdir(\"C:/Users/Shahram/Desktop/Microsoft Spam/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The train.CSV file is almost 4GB. \n",
    "* Initially, I could not read the file as a whole so read the data in small chunks to figure out the columns and its content.\n",
    "* After discussing with Debadyuti, he suggested to define the Types of columns and then use the Pandas read_csv to read all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2c52e2333e75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/Shahram/Desktop/Microsoft Spam/train.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1152\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2057\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2058\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2059\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2060\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2061\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._concatenate_chunks\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\dtypes.py\u001b[0m in \u001b[0;36m__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    368\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[1;31m# We *do* want to include the real self.ordered here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hash_categories\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ordered\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\dtypes.py\u001b[0m in \u001b[0;36m_hash_categories\u001b[1;34m(categories, ordered)\u001b[0m\n\u001b[0;32m    452\u001b[0m                 \u001b[0mcategories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_NS_DTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m             \u001b[0mcat_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhash_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mordered\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m             cat_array = np.vstack(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\util\\hashing.py\u001b[0m in \u001b[0;36mhash_array\u001b[1;34m(vals, encoding, hash_key, categorize)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m             \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhashing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhash_object_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhash_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m             \u001b[1;31m# we have mixed types\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashing.pyx\u001b[0m in \u001b[0;36mpandas._libs.hashing.hash_object_array\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\hashing.cp37-win_amd64.pyd\u001b[0m in \u001b[0;36mView.MemoryView.memoryview_cwrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\hashing.cp37-win_amd64.pyd\u001b[0m in \u001b[0;36mView.MemoryView.memoryview.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dtypes = {\n",
    "        'MachineIdentifier':                                    'category',\n",
    "        'ProductName':                                          'category',\n",
    "        'EngineVersion':                                        'category',\n",
    "        'AppVersion':                                           'category',\n",
    "        'AvSigVersion':                                         'category',\n",
    "        'IsBeta':                                               'int8',\n",
    "        'RtpStateBitfield':                                     'float16',\n",
    "        'IsSxsPassiveMode':                                     'int8',\n",
    "        'DefaultBrowsersIdentifier':                            'float32',\n",
    "        'AVProductStatesIdentifier':                            'float32',\n",
    "        'AVProductsInstalled':                                  'float16',\n",
    "        'AVProductsEnabled':                                    'float16',\n",
    "        'HasTpm':                                               'int8',\n",
    "        'CountryIdentifier':                                    'int16',\n",
    "        'CityIdentifier':                                       'float32',\n",
    "        'OrganizationIdentifier':                               'float16',\n",
    "        'GeoNameIdentifier':                                    'float16',\n",
    "        'LocaleEnglishNameIdentifier':                          'int16',\n",
    "        'Platform':                                             'category',\n",
    "        'Processor':                                            'category',\n",
    "        'OsVer':                                                'category',\n",
    "        'OsBuild':                                              'int16',\n",
    "        'OsSuite':                                              'int16',\n",
    "        'OsPlatformSubRelease':                                 'category',\n",
    "        'OsBuildLab':                                           'category',\n",
    "        'SkuEdition':                                           'category',\n",
    "        'IsProtected':                                          'float16',\n",
    "        'AutoSampleOptIn':                                      'int8',\n",
    "        'PuaMode':                                              'category',\n",
    "        'SMode':                                                'float16',\n",
    "        'IeVerIdentifier':                                      'float16',\n",
    "        'SmartScreen':                                          'category',\n",
    "        'Firewall':                                             'float16',\n",
    "        'UacLuaenable':                                         'float64', # was 'float32'\n",
    "        'Census_MDC2FormFactor':                                'category',\n",
    "        'Census_DeviceFamily':                                  'category',\n",
    "        'Census_OEMNameIdentifier':                             'float32', # was 'float16'\n",
    "        'Census_OEMModelIdentifier':                            'float32',\n",
    "        'Census_ProcessorCoreCount':                            'float16',\n",
    "        'Census_ProcessorManufacturerIdentifier':               'float16',\n",
    "        'Census_ProcessorModelIdentifier':                      'float32', # was 'float16'\n",
    "        'Census_ProcessorClass':                                'category',\n",
    "        'Census_PrimaryDiskTotalCapacity':                      'float64', # was 'float32'\n",
    "        'Census_PrimaryDiskTypeName':                           'category',\n",
    "        'Census_SystemVolumeTotalCapacity':                     'float64', # was 'float32'\n",
    "        'Census_HasOpticalDiskDrive':                           'int8',\n",
    "        'Census_TotalPhysicalRAM':                              'float32',\n",
    "        'Census_ChassisTypeName':                               'category',\n",
    "        'Census_InternalPrimaryDiagonalDisplaySizeInInches':    'float32', # was 'float16'\n",
    "        'Census_InternalPrimaryDisplayResolutionHorizontal':    'float32', # was 'float16'\n",
    "        'Census_InternalPrimaryDisplayResolutionVertical':      'float32', # was 'float16'\n",
    "        'Census_PowerPlatformRoleName':                         'category',\n",
    "        'Census_InternalBatteryType':                           'category',\n",
    "        'Census_InternalBatteryNumberOfCharges':                'float64', # was 'float32'\n",
    "        'Census_OSVersion':                                     'category',\n",
    "        'Census_OSArchitecture':                                'category',\n",
    "        'Census_OSBranch':                                      'category',\n",
    "        'Census_OSBuildNumber':                                 'int16',\n",
    "        'Census_OSBuildRevision':                               'int32',\n",
    "        'Census_OSEdition':                                     'category',\n",
    "        'Census_OSSkuName':                                     'category',\n",
    "        'Census_OSInstallTypeName':                             'category',\n",
    "        'Census_OSInstallLanguageIdentifier':                   'float16',\n",
    "        'Census_OSUILocaleIdentifier':                          'int16',\n",
    "        'Census_OSWUAutoUpdateOptionsName':                     'category',\n",
    "        'Census_IsPortableOperatingSystem':                     'int8',\n",
    "        'Census_GenuineStateName':                              'category',\n",
    "        'Census_ActivationChannel':                             'category',\n",
    "        'Census_IsFlightingInternal':                           'float16',\n",
    "        'Census_IsFlightsDisabled':                             'float16',\n",
    "        'Census_FlightRing':                                    'category',\n",
    "        'Census_ThresholdOptIn':                                'float16',\n",
    "        'Census_FirmwareManufacturerIdentifier':                'float16',\n",
    "        'Census_FirmwareVersionIdentifier':                     'float32',\n",
    "        'Census_IsSecureBootEnabled':                           'int8',\n",
    "        'Census_IsWIMBootEnabled':                              'float16',\n",
    "        'Census_IsVirtualDevice':                               'float16',\n",
    "        'Census_IsTouchEnabled':                                'int8',\n",
    "        'Census_IsPenCapable':                                  'int8',\n",
    "        'Census_IsAlwaysOnAlwaysConnectedCapable':              'float16',\n",
    "        'Wdft_IsGamer':                                         'float16',\n",
    "        'Wdft_RegionIdentifier':                                'float16',\n",
    "        'HasDetections':                                        'int8'\n",
    "        }\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"C:/Users/Shahram/Desktop/Microsoft Spam/train.csv\", dtype=dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ref: https://www.kaggle.com/c/microsoft-malware-prediction/discussion/76384#449402\n",
    "\n",
    "base_url = 'https://www.microsoft.com/en-us/wdsi/definitions/antimalware-definition-release-notes?RequestVersion='\n",
    "#read the data the delete it then..\n",
    "#do the same for test set as well..\n",
    "\n",
    "df = pd.read_csv('train.csv', usecols=['AvSigVersion'])\n",
    "search_ver = np.asarray(list(set(df['AvSigVersion'].values)))\n",
    "del df\n",
    "\n",
    "print(len(search_ver))\n",
    "\n",
    "saved, cnt = {}, 0\n",
    "\n",
    "for i in search_ver:\n",
    "    if cnt%200 == 0:\n",
    "        print('Done till', cnt, 'out of', len(search_ver))\n",
    "\n",
    "    page = requests.get(base_url+i)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    try:\n",
    "        saved[i] = soup.find(id='availabledate').contents[0][28:]\n",
    "    except Exception:\n",
    "        print('Didn\\'t Find For', i)\n",
    "    cnt+= 1\n",
    "np.save('train_AvSigVersion.npy', saved)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT TIMESTAMP DICTIONARY\n",
    "datedict = np.load('C:/Users/Shahram/Desktop/Microsoft Spam/AvSigVersionTimestamps.npy', allow_pickle=True)\n",
    "datedict = datedict[()]\n",
    "# ADD TIMESTAMPS\n",
    "train['Date'] = train['AvSigVersion'].map(datedict)\n",
    "#df_test['Date'] = df_test['AvSigVersion'].map(datedict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see the data and its columns:\n",
    "* There are almost 8.921 Million records with 83 columns. Memory usage is around 1.9 GB. the columns type is as we defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will explore the number of unique products and the Engione version in this data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print (\"There are\", len (train.ProductName.unique().tolist()), \"distinct products.\", train.ProductName.unique().tolist())\n",
    "print (\"There are\", len (train.EngineVersion.unique()), \"distinct version of these products.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at distribution of the Devices where a malware has been detected.\n",
    "#### It is clear that the there is equal distribution of devices with malware detected and device without any malware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero = (train['HasDetections']==0).sum()\n",
    "One  = (train['HasDetections']==1).sum()\n",
    "sizes = [Zero,One]\n",
    "labels = ['Zero','One']\n",
    "fig1, ax1 = plt.subplots()\n",
    "plt.title(\"Check the dsitribution of whether Devices have Detection or not\", fontdict=None, loc='center', pad=None, color = \"azure\")\n",
    "ax1.pie(sizes, labels = labels, autopct='%1.1f%%',shadow=True, startangle=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see which columns are binary: \n",
    "###### I wrote the code myself but got help from https://www.kaggle.com/datark1/malware-prediction-eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BinaryColumns = []\n",
    "for column in train.select_dtypes (include = ['int8', 'int16', 'int32', 'int16', 'float32', 'float64']):\n",
    "    if ( train [column].min()) == 0 or (train[column].max() == 1):\n",
    "        BinaryColumns.append (column)\n",
    "        #print (column)\n",
    "print ('There are', len(BinaryColumns),'columns which are Binary.')\n",
    "BinaryColumns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's visually look at the percentage of zeros and ones in Digital columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "for i, num in zip(BinaryColumns, range(1,20)):\n",
    "    Zero = (train[i]==0).sum()\n",
    "    One = (train[i]==1).sum()\n",
    "    sizes = [Zero,One]\n",
    "    labels = ['Zero','One']\n",
    "    ax = fig.add_subplot(4,4,num) #fig1, ax1 = plt.subplots()\n",
    "    plt.title(i, fontdict=None, loc='center', pad=None, color = \"azure\")\n",
    "    ax.pie(sizes, labels = labels, autopct='%1.1f%%',shadow=True, startangle=90)\n",
    "    ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We should take a look to see if the columns are correlated.\n",
    "##### As one can see aside from few columns ( which are in the vicinity of each other, the rest of the data are NOT Correlated.\n",
    "##### Few columns are negatively correlated. (e.g.: RtpStateBitField - IsSXSPassiveMode)\n",
    "\n",
    "\n",
    "#### Reference: https://towardsdatascience.com/better-heatmaps-and-correlation-matrix-plots-in-python-41445d0f2bec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corr = train.corr()\n",
    "plt.figure(figsize=(22,12))\n",
    "ax = sns.heatmap(corr, vmin=-1, vmax=1, center=0, cmap=sns.diverging_palette(20, 220, n=200), square=True)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting the number of Null values in columns and calculating the percentages\n",
    "#### We can use this conclusion to find out which columns we can drop from our calculations.\n",
    "#### As one can see, there are 7 columns with more than 50% row of null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoEmptyRows = []\n",
    "percentages = []\n",
    "ColumnType = []\n",
    "\n",
    "for col in train:\n",
    "    ColumnType.append(train[col].dtype)\n",
    "    NoEmptyRows.append(train[col].isnull().sum())\n",
    "    percentages.append((train[col].isnull().sum()/train.shape[0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MissingValueTable = pd.DataFrame ({'Column Name': train.columns, 'Data Type': ColumnType, \n",
    "                                   'Number of Empty Rows': NoEmptyRows,'Percentages':percentages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MissingValueTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Missing Value Percentages\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title(\"Percentage of Null counts in columns\", fontdict=None, loc='center', pad=None)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.bar(x = MissingValueTable['Column Name'], height = MissingValueTable['Percentages'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's group infected machines by the \"platform\".\n",
    "#### Windows 10 is the major infected platform with more than 4 million machines infected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group = ['Platform', 'HasDetections']\n",
    "test = train.groupby(group).size().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test = pd.DataFrame (test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Missing Value Percentages\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"Machine counts\", fontdict=None, loc='center', pad=None)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.ylabel(\"Number of machines\") #ax.set_ylabel('Probability density')\n",
    "sns.barplot(x = test.index, y = Test[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's group infected machines by Form Factor.\n",
    "\n",
    "#### It is clear that Notebooks are majorly hit by malwares and then desktops and convertibles stand second and third respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group = ['Census_MDC2FormFactor', 'HasDetections']\n",
    "test = train.groupby(group).size().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test = pd.DataFrame (test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Missing Value Percentages\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"Machine counts by Form Factor\", fontdict=None, loc='center', pad=None)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.ylabel(\"Number of machines\") \n",
    "sns.barplot(x = test.index, y = Test[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's group infected machines by whether they are a Gamer or not.\n",
    "#### It is clear that the gamer machine (wehether infected or not) are more than half of the non-gamers. Clearly, among the gamer machine infection is more (probable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group = ['Wdft_IsGamer', 'HasDetections']\n",
    "test = train.groupby(group).size().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test = pd.DataFrame (test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Missing Value Percentages\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"Machine counts by whether it is a gaming machine\", fontdict=None, loc='center', pad=None)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.ylabel(\"Number of machines\") \n",
    "sns.barplot(x = test.index, y = Test[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BinaryColumns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CategoryColumns = train.select_dtypes (include = ['category']).columns\n",
    "# CategoryColumns\n",
    "BinaryColumns.extend(CategoryColumns)\n",
    "CategoryColumns\n",
    "# BinaryColumns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ColumnsExcluded = train.columns.difference(BinaryColumns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "for i, num in zip(ColumnsExcluded, range(1,30)):\n",
    "    \n",
    "    ax = fig.add_subplot(5,6,num) #fig1, ax1 = plt.subplots()\n",
    "    plt.title(i, fontdict=None, loc='center', pad=None, color = \"azure\")\n",
    "    sns.distplot(train[i].dropna())\n",
    "    #ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "* We used the data in Microsoft Malware database.\n",
    "* The data contain around 8.92 million record and 83 column. Fifteen columns are binary. We made a pie chart to see the distributoion of the Binary columns.\n",
    "* The Target column which is HasDetectiosn is equally distributed.\n",
    "* We graphed the heatmap of correlation of columns and saw that few columns are correlted. (Two columns are strongly negatively correlated and a few are positivley correlated.)\n",
    "* we also grahphed the malware infected devices by platform and Form Factor and Windows versio.\n",
    "* Windos 10 and laptops are the most infected machines.\n",
    "* We also graphed the histogram of the rmeainning columns to see the distribution of the data.\n",
    "* Few columns (around 7) have more than 50% of their data mssining (Null value) and hence might be a good idea to ignore them in the data engineering. We ideate that the other columns with less missing values can be filled with mean or median of the column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The rest of this note book is related to Feature Engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I am going to drop the columns with more than 10% missing vlaues which are around 9 or 10 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"There are \", (MissingValueTable['Percentages']>=10).sum(), \"columns with more than 10 % of rows with missing values.\")\n",
    "MissingValueTable [(MissingValueTable['Percentages']>=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(MissingValueTable [(MissingValueTable['Percentages']>=10)]['Column Name'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are 35 columns with between 0 to 10 % rows missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MissingValueTable [(MissingValueTable['Percentages']<=10) & (MissingValueTable['Percentages']>0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MissingValueTable [(MissingValueTable['Percentages']<=10) & (MissingValueTable['Percentages']>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColumnsWMissingValue = MissingValueTable [(MissingValueTable['Percentages']<=10) & (MissingValueTable['Percentages']>0)] #['Column Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColumnsWMissingValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of Categorical columns with between 0 - 10 percent missing rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColumnsWMissingValue.loc [ColumnsWMissingValue['Data Type'] =='category']['Column Name'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since we cannot impute text at the moment, We are going to remove any rows with missing value in the categorical columns and then take a 1 or 2% sample from the rest of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train [ColumnsWMissingValue.loc [ColumnsWMissingValue['Data Type'] =='category']['Column Name'].tolist()].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ColumnsWMissingValue.loc [ColumnsWMissingValue['Data Type'] =='category']['Column Name'].tolist()\n",
    "train1 = train.dropna (subset = ColumnsWMissingValue.loc [ColumnsWMissingValue['Data Type'] =='category']['Column Name'].tolist() , axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 [ColumnsWMissingValue.loc [ColumnsWMissingValue['Data Type'] =='category']['Column Name'].tolist()].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 [ColumnsWMissingValue.loc [ColumnsWMissingValue['Data Type'] =='category']['Column Name'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train1.sample(frac=0.02,random_state=200) #random state is a seed value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will be imputating Using Multivariate Imputation by Chained Equation.\n",
    "* Ref: https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColumnsWMissingValue['Column Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumColumnWMissingValue1 = train2 [ColumnsWMissingValue['Column Name']].select_dtypes(exclude='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumColumnWMissingValue1.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Tried Multivariate Imputation but found it to be slow \n",
    "from impyute.imputation.cs import mice\n",
    "imputed_training = mice(NumColumnWMissingValue1.values)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp_mean = SimpleImputer(strategy='mean') \n",
    "imp_mean.fit(NumColumnWMissingValue)\n",
    "imputed_train_df = imp_mean.transform(NumColumnWMissingValue)\n",
    "\n",
    "dataset = pd.DataFrame(imputed_training)\n",
    "\n",
    "dataset.columns = NumColumnWMissingValue1.columns.tolist()\n",
    "\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumColumnWMissingValue1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BinaryColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in NumColumnWMissingValue1.columns.tolist():\n",
    "    if col in BinaryColumns:\n",
    "        print (col, 'Binary')\n",
    "        print (train2[col].mode())\n",
    "    else:\n",
    "        \n",
    "        print ('Not in Binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 ['Census_PrimaryDiskTotalCapacity'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in NumColumnWMissingValue1.columns.tolist():\n",
    "    if col in BinaryColumns:\n",
    "        train2[col].fillna(train2[col].mode(), inplace = True)\n",
    "    else:\n",
    "        train2[col] =  train2[col].astype (dtype = 'float32')\n",
    "        train2[col].fillna(train2[col].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train2['RtpStateBitfield'].fillna(train2['RtpStateBitfield'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let digitize the categorical columns with one hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2.select_dtypes(include='category').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns = train2.select_dtypes(include='category').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Categorical_Columns = ['ProductName', 'Platform', 'Processor', 'Census_OSArchitecture',\n",
    "                       'Census_FlightRing','Census_GenuineStateName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop_columns = [x for x in train_columns if x not in Categorical_Columns]\n",
    "print (Drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train2.drop (Drop_columns, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2[Categorical_Columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2[Categorical_Columns] = train2[Categorical_Columns].astype ('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2[Categorical_Columns].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Categorical_Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3 = pd.get_dummies (train2[Categorical_Columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train2.drop (Categorical_Columns, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train4 = pd.concat([train2, train3], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(train4, test_size=0.3)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train4.loc[:, train4.columns != 'HasDetections'].columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['HasDetections']\n",
    "X_train = train[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test['HasDetections']\n",
    "X_test = test[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ref: https://towardsdatascience.com/a-beginners-guide-to-xgboost-87f5d4c30ed7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shahram\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\Shahram\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    }
   ],
   "source": [
    "D_train = xgb.DMatrix(X_train, label=y_train)\n",
    "D_test = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 10,  \n",
    "    'objective': 'multi:softprob',  \n",
    "    'num_class': 5} \n",
    "\n",
    "steps = 20  # The number of training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.train(param, D_train, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.60936054322367\n",
      "Recall = 0.6076987003749696\n",
      "Accuracy = 0.6075096817646068\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "preds = model.predict(D_test)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "print(\"Precision = {}\".format(precision_score(y_test, best_preds, average='macro')))\n",
    "print(\"Recall = {}\".format(recall_score(y_test, best_preds, average='macro')))\n",
    "print(\"Accuracy = {}\".format(accuracy_score(y_test, best_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ref: https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "d_train = lgb.Dataset(X_train, label=y_train)\n",
    "params = {}\n",
    "params['learning_rate'] = 0.003\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['objective'] = 'binary'\n",
    "params['metric'] = 'binary_logloss'\n",
    "params['sub_feature'] = 0.5\n",
    "params['num_leaves'] = 100\n",
    "params['min_data'] = 50\n",
    "params['max_depth'] = 100\n",
    "clf = lgb.train(params, d_train, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction\n",
    "y_pred=clf.predict(X_test)\n",
    "#convert into binary values\n",
    "for i in range(0,99):\n",
    "    if y_pred[i]>=.5:       # setting threshold to .5\n",
    "       y_pred[i]=1\n",
    "    else:  \n",
    "       y_pred[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "#Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy=accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty = 'l1', C = 10,random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Apply logistic regression on the split train/test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute your model’s accuracy using accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(accuracy_score(y_test,y_predict),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
